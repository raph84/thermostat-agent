{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit ('.venv')",
   "metadata": {
    "interpreter": {
     "hash": "af342d947b4e0a8d20dab91834eabbe31804cf708f7b5f5dacaf6d4e8abeceb5"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"C:\\\\Users\\\\T834432\\\\Documents\\\\personnel\\\\thermostat\\\\thermostat-agent\\\\thermostat-292016-05700c0efdbe__.json\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PROJECT_ID\"] = \"thermostat-292016\"\n",
    "os.environ[\"ACTION_THRESHOLD\"] = \"1.0\"\n",
    "\n",
    "from google.cloud import storage\n",
    "#from thermostat import get_metric_list_from_bucket, bucket_name, storage_client\n",
    "from yadt import parse_date, apply_tz_toronto\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiates a client\n",
    "storage_client = storage.Client()\n",
    "# The name for the new bucket\n",
    "bucket = storage_client.bucket(\"thermostat_metric_data\")\n",
    "\n",
    "b = bucket.get_blob('aggregate.p')\n",
    "\n",
    "pickle_load = b.download_as_bytes()\n",
    "agg2 = pickle.loads(pickle_load)\n",
    "agg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "agg2['Direct Solar Rad.'].interpolate(limit=12, inplace=True)\n",
    "agg2_nan = agg2[agg2.isna().any(axis=1)]\n",
    "ind_temp_na = agg2[agg2['Indoor Temp.'].isna()]\n",
    "pd.set_option('display.max_columns', 25)\n",
    "index_drop = []\n",
    "index_drop.append(ind_temp_na.index)\n",
    "agg2 = agg2.drop(index=ind_temp_na.index)\n",
    "pickle_dump = pickle.dumps(agg2)\n",
    "b = bucket.get_blob('aggregate.p')\n",
    "b.temporary_hold = False\n",
    "b.patch()\n",
    "b.upload_from_string(data=pickle_dump, content_type='text/plain')\n",
    "agg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg2.drop(agg2.tail(1).index)\n",
    "agg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg2['dup'] = agg2.index.duplicated(keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dup = agg2.copy(deep=True)[agg2['dup'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.max_columns', 25)\n",
    "#dup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg2 = agg2[~agg2.index.duplicated(keep='first')]\n",
    "pickle_dump = pickle.dumps(agg2)\n",
    "b = bucket.get_blob('aggregate.p')\n",
    "b.temporary_hold = False\n",
    "b.patch()\n",
    "b.upload_from_string(data=pickle_dump, content_type='text/plain')\n",
    "agg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in agg2.columns:\n",
    "    if c.startswith('action_t'):\n",
    "        agg2.drop(columns=[c], inplace=True)\n",
    "    if c.startswith('mpc_'):\n",
    "        agg2.drop(columns=[c], inplace=True)\n",
    "    if c.startswith('heating_'):\n",
    "        agg2.drop(columns=[c], inplace=True)\n",
    "\n",
    "    if c.startswith('action'):\n",
    "        agg2.drop(columns=[c], inplace=True)\n",
    "    if c.startswith('indoor_temp'):\n",
    "        agg2.drop(columns=[c], inplace=True)\n",
    "    if c.startswith('sat_stpt'):\n",
    "        agg2.drop(columns=[c], inplace=True)\n",
    "    if c.startswith('sys_out_temp'):\n",
    "        agg2.drop(columns=[c], inplace=True)\n",
    "\n",
    "\n",
    "agg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "current_date = parse_date(\"2021-01-01T23:45:00-0500\")\n",
    "mpc = {\n",
    "    \"action_threshold\": 1.0,\n",
    "    \"heating_state\": False,\n",
    "    \"mpc_action\": 0.24015000020290925,\n",
    "    \"mpc_indoor_temp\": 18.63394,\n",
    "    \"mpc_indoor_temp_setpoint\": 18.0,\n",
    "    \"mpc_occupancy_flag\": 0,\n",
    "    \"mpc_sat_stpt\": 0.24015000020290925,\n",
    "    \"mpc_sys_out_temp\": 19.48333333333333\n",
    "}\n",
    "\n",
    "\n",
    "del mpc[\"mpc_indoor_temp\"]\n",
    "del mpc[\"mpc_occupancy_flag\"]\n",
    "\n",
    "\n",
    "#decision = {\n",
    "#            \"heating_state\" : None,\n",
    "#            \"action_threshold\" : None\n",
    "#    }\n",
    "\n",
    "#concat = dict(chain.from_iterable(d.items() for d in (mpc, decision)))\n",
    "\n",
    "agg_mpc = pd.DataFrame(mpc, index=[current_date])\n",
    "\n",
    "agg2 = pd.concat([agg2, agg_mpc.reindex(agg2.index)], axis=1)\n",
    "#agg2.update(agg_mpc)\n",
    "agg2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metric_from_bucket(blob):\n",
    "\n",
    "    last_json = []\n",
    "    \n",
    "    try:\n",
    "        json_str = blob.download_as_bytes()\n",
    "        j = json.loads(json_str)\n",
    "        #j['dt'] = apply_tz_toronto(datetime.fromtimestamp(j['timestamp']))\n",
    "        \n",
    "        #if len(list(j.keys())) > 0:\n",
    "        #    if 'sound' in j.keys():\n",
    "        #        del j['sound']\n",
    "        #    if 'timestamp'\n",
    "        #    del j['timestamp']\n",
    "        if isinstance(j, list):\n",
    "            for item in j:\n",
    "                last_json.append(item)\n",
    "        else:\n",
    "            last_json.append(j)\n",
    "            \n",
    "    except json.JSONDecodeError:\n",
    "        pass\n",
    "\n",
    "    return last_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "###\n",
    "###\n",
    "###\n",
    "bucket_name = \"thermostat_metric_data\"\n",
    "end_date = \"2021-01-02T21:00:00-0500\"\n",
    "end_date = parse_date(end_date)\n",
    "metric_list = list(storage_client.list_blobs(bucket_name, prefix='thermostat'))\n",
    "metric_list.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_selection_realtime(dt):\n",
    "    selection_end = end_date\n",
    "\n",
    "    select = True\n",
    "    end = False\n",
    "    if dt < selection_end:\n",
    "        #print(dt)\n",
    "        select = False\n",
    "        end = True\n",
    "\n",
    "    return select, end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregator(blob_list, date_function, value_function, date_select_function):\n",
    "    aggregation = pd.DataFrame()\n",
    "\n",
    "    for m in blob_list:\n",
    "        metric_json = get_metric_from_bucket(m) \n",
    "        print(m.name)\n",
    "        for item in metric_json:\n",
    "\n",
    "            #need data from filename\n",
    "            if m.name.startswith('environment_sensor_basement-'):\n",
    "                item['location'] = 'house.basement'\n",
    "                str_date = m.name.replace('environment_sensor_basement-','')\n",
    "                item['dt'] = parse_date(str_date)\n",
    "            \n",
    "            date_function(item)\n",
    "            metric_dict = value_function(item)\n",
    "            \n",
    "            select, end = date_select_function(metric_dict['dt'])\n",
    "            if select:\n",
    "                df = pd.DataFrame(metric_dict,index=[metric_dict['dt']])\n",
    "                aggregation = aggregation.append(df)\n",
    "\n",
    "            if end:\n",
    "                break\n",
    "        if end:\n",
    "            break\n",
    "            \n",
    "    return aggregation\n",
    "\n",
    "def value_function_thermostat(i):\n",
    "    if 'sound' in i.keys():\n",
    "        del i['sound']\n",
    "    if 'timestamp' in i.keys():\n",
    "        del i['timestamp']\n",
    "    return i\n",
    "\n",
    "def date_function_thermostat(i):\n",
    "    i['dt'] = apply_tz_toronto(datetime.fromtimestamp(i['timestamp']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "thermostat_agg = aggregator(metric_list, date_function_thermostat, value_function_thermostat, date_selection_realtime)\n",
    "pickle.dump( thermostat_agg, open( \"thermostat_agg.p\", \"wb\" ) )\n",
    "thermostat_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_file(payload, filename):\n",
    "    \"\"\"Create a file.\n",
    "\n",
    "  The retry_params specified in the open call will override the default\n",
    "  retry params for this particular file handle.\n",
    "\n",
    "  Args:\n",
    "    filename: filename.\n",
    "  \"\"\"\n",
    "    blob = bucket.blob(filename)\n",
    "\n",
    "    blob.upload_from_string(data=payload,\n",
    "                            content_type='text/plain')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiates a client\n",
    "#storage_client = storage.Client()\n",
    "\n",
    "# The name for the new bucket\n",
    "#bucket_name = \"thermostat_metric_data\"\n",
    "#bucket = storage_client.bucket(bucket_name)\n",
    "\n",
    "#pickle_dump = pickle.dumps(agg2)\n",
    "#create_file(pickle_dump, 'aggregate.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump( thermostat_agg, open( \"thermostat_agg.p\", \"wb\" ) )\n",
    "thermostat_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_climacell = \"climacell_data\"\n",
    "realtime_list = list(storage_client.list_blobs(bucket_climacell, prefix='realtime'))\n",
    "realtime_list.reverse()\n",
    "\n",
    "def date_function_climacell(i):\n",
    "    #print(i)\n",
    "    i['dt'] = parse_date(i['observation_time']['value'])\n",
    "    del i['observation_time']\n",
    "    #\"observation_time\": {\"value\": \"2020-10-18T21:15:02.777Z\"}}¸\n",
    "\n",
    "def value_function_climacell(i):\n",
    "    #print(i)\n",
    "    field = ['temp','humidity','wind_speed','wind_direction','surface_shortwave_radiation']\n",
    "    if 'observation_time' in i.keys():\n",
    "        field.append('observation_time')\n",
    "    else:\n",
    "        field.append('dt')\n",
    "\n",
    "    value_dict = {}\n",
    "\n",
    "    for f in field:\n",
    "        if f != 'dt':\n",
    "            value_dict[f] = i[f]['value']\n",
    "        else:\n",
    "            value_dict[f] = i[f]\n",
    "\n",
    "    return value_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "###\n",
    "###\n",
    "###\n",
    "realtime_agg = aggregator(realtime_list, date_function_climacell, value_function_climacell, date_selection_realtime)\n",
    "realtime_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_climacell_columns(data):\n",
    "    data.rename(columns={'humidity':'Outdoor RH', \n",
    "                                'temp':'Outdoor Temp',\n",
    "                                'surface_shortwave_radiation':'Direct Solar Rad.',\n",
    "                                'wind_speed':'Wind Speed',\n",
    "                                'wind_direction':'Wind Direction'}, inplace = True)\n",
    "rename_climacell_columns(realtime_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stove = thermostat_agg.copy(deep=True)[thermostat_agg['location'] == 'house.basement.stove'][['dt','stove_exhaust_temp']]\n",
    "t_a = thermostat_agg.copy(deep=True)[thermostat_agg['location'] != 'house.basement.stove']\n",
    "t_a.sort_values('dt', inplace=True)\n",
    "stove.sort_values('dt', inplace=True)\n",
    "del t_a['stove_exhaust_temp']\n",
    "del t_a['location']\n",
    "agg = pd.merge_asof(t_a, stove,left_on='dt',right_on='dt',direction=\"nearest\")\n",
    "agg.set_index('dt', inplace=True)\n",
    "agg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg.sort_values('dt',inplace=True)\n",
    "realtime_agg.sort_values('dt',inplace=True)\n",
    "agg = pd.merge_asof(agg, realtime_agg,left_on='dt',right_on='dt',direction=\"nearest\")\n",
    "agg.set_index('dt', inplace=True)\n",
    "agg = agg[~agg.index.duplicated(keep='first')]\n",
    "#agg['dup'] = agg.index.duplicated(keep=False)\n",
    "#agg = agg[agg['dup']]\n",
    "#agg.sort_values('dt',inplace=True)\n",
    "agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "####\n",
    "####\n",
    "#agg2 = agg.copy(deep=True).resample('15Min').interpolate(method='linear')\n",
    "#m.set_index('dt', inplace=True)\n",
    "agg2 = agg.copy(deep=True).resample('15Min').mean()\n",
    "agg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_index = agg.index.max()\n",
    "start_index = agg.index[agg2.index.searchsorted(end_index - pd.Timedelta(value=3, unit='hours'))]\n",
    "print(start_index)\n",
    "print(end_index)\n",
    "agg_motion = agg.copy()[start_index:end_index]\n",
    "#agg_motion\n",
    "\n",
    "\n",
    "m = agg_motion[['motion']]\n",
    "m['motion'] = m['motion'].apply(lambda x: 1 if x else 0)\n",
    "m = m.resample('3min').sum()\n",
    "# Normalize values\n",
    "m['motion'] = (m['motion']-m['motion'].min())/(m['motion'].max()-m['motion'].min())\n",
    "# Exponential decay\n",
    "m['motion'] = m['motion'].ewm(halflife='6Min', times=m.index).mean()\n",
    "m = m[['motion']].resample('15min').sum()\n",
    "# Values bellow 50 quantile will be False\n",
    "m['quantile'] = m['motion'].quantile(q=0.50)\n",
    "#m['motion'] = m.apply(lambda x: True if x['motion'] > x['quantile'] else False, axis=1)\n",
    "#del m['quantile']\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "####\n",
    "####\n",
    "agg2 = agg2.merge(m, left_index=True, right_index=True)\n",
    "agg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "hourly_start = agg2.index.max().to_pydatetime()\n",
    "hourly_end = hourly_start + timedelta(hours=4)\n",
    "\n",
    "def date_selection_hourly(dt):\n",
    "    select = False\n",
    "    end = False\n",
    "\n",
    "    \n",
    "    if dt <= hourly_end and dt >= hourly_start:\n",
    "        select = True\n",
    "\n",
    "    if dt > hourly_end:\n",
    "        end = True\n",
    "\n",
    "    return select, end\n",
    "\n",
    "hourly_list = list(storage_client.list_blobs(bucket_climacell, prefix='hourly'))\n",
    "hourly_list.reverse()\n",
    "\n",
    "\n",
    "\n",
    "hourly_agg = aggregator(hourly_list, date_function_climacell, value_function_climacell, date_selection_hourly)\n",
    "rename_climacell_columns(hourly_agg)\n",
    "hourly_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_metric_from_bucket(blob):\n",
    "\n",
    "    last_json = []\n",
    "\n",
    "    try:\n",
    "        json_str = blob.download_as_bytes()\n",
    "        j = json.loads(json_str)\n",
    "        #j['dt'] = apply_tz_toronto(datetime.fromtimestamp(j['timestamp']))\n",
    "\n",
    "        #if len(list(j.keys())) > 0:\n",
    "        #    if 'sound' in j.keys():\n",
    "        #        del j['sound']\n",
    "        #    if 'timestamp'\n",
    "        #    del j['timestamp']\n",
    "        if isinstance(j, list):\n",
    "            for item in j:\n",
    "                last_json.append(item)\n",
    "        else:\n",
    "            last_json.append(j)\n",
    "\n",
    "    except json.JSONDecodeError:\n",
    "        pass\n",
    "\n",
    "    return last_json\n",
    "\n",
    "\n",
    "def aggregator(blob_list, date_function, value_function, date_select_function, end_date, start_date=None):\n",
    "    aggregation = pd.DataFrame()\n",
    "\n",
    "    for m in blob_list:\n",
    "        metric_json = get_metric_from_bucket(m)\n",
    "        print(m.name)\n",
    "        for item in metric_json:\n",
    "\n",
    "            #need data from filename\n",
    "            if m.name.startswith('environment_sensor_basement-'):\n",
    "                item['location'] = 'house.basement'\n",
    "                str_date = m.name.replace('environment_sensor_basement-','')\n",
    "                item['dt'] = parse_date(str_date, toronto=True)\n",
    "\n",
    "            date_function(item)\n",
    "            metric_dict = value_function(item)\n",
    "\n",
    "            select, end = date_select_function(metric_dict['dt'], end_date, start_date)\n",
    "            if select:\n",
    "                df = pd.DataFrame(metric_dict, index=[metric_dict['dt']])\n",
    "                aggregation = aggregation.append(df)\n",
    "\n",
    "            if end:\n",
    "                break\n",
    "        if end:\n",
    "            break\n",
    "\n",
    "    return aggregation\n",
    "\n",
    "\n",
    "# Instantiates a client\n",
    "storage_client = storage.Client()\n",
    "# The name for the new bucket\n",
    "bucket = storage_client.bucket(\"thermostat_metric_data\")\n",
    "\n",
    "basement = agg2.index.min().to_pydatetime()\n",
    "\n",
    "\n",
    "if pd.isnull(basement):\n",
    "    end_date = \"2020-12-28T12:00:00-0500\"\n",
    "    end_date = parse_date(end_date)\n",
    "else:\n",
    "    end_date = basement\n",
    "\n",
    "print(\"end_date : {}\".format(end_date))\n",
    "\n",
    "def date_selection_realtime(dt, end_date, start_date):\n",
    "    selection_end = end_date\n",
    "\n",
    "    select = True\n",
    "    end = False\n",
    "    if dt < selection_end:\n",
    "        #print(dt)\n",
    "        select = False\n",
    "        end = True\n",
    "\n",
    "    return select, end\n",
    "\n",
    "def value_function_basement(i):\n",
    "\n",
    "    i['temp_basement'] = i['temperature']\n",
    "    del i['temperature']\n",
    "    del i['original_payload']\n",
    "\n",
    "    return i\n",
    "\n",
    "\n",
    "def date_function_basement(i):\n",
    "    return\n",
    "\n",
    "basement_list = list(storage_client.list_blobs(bucket, prefix='environment_sensor_basement-'))\n",
    "basement_list.reverse()\n",
    "\n",
    "basement_agg = aggregator(basement_list, date_function_basement,\n",
    "                        value_function_basement,\n",
    "                        date_selection_realtime,\n",
    "                        end_date)\n",
    "\n",
    "basement_agg = basement_agg.resample('15Min').mean()\n",
    "basement_agg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basement_agg = basement_agg.resample('15Min').mean()\n",
    "#del agg2['temp_basement']\n",
    "agg2 = agg2.merge(basement_agg, left_index=True, right_index=True)\n",
    "agg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_dump = pickle.dumps(agg2)\n",
    "b = bucket.get_blob('aggregate.p')\n",
    "b.temporary_hold = True\n",
    "b.patch()\n",
    "b.upload_from_string(data=pickle_dump, content_type='text/plain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thermostat_agg = pickle.load( open( \"thermostat_agg.p\", \"rb\" ) )\n",
    "thermostat_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "thermthermostat_agg = thermostat_agg.merge(basement_agg, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thermthermostat_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg2 = agg2.replace({np.nan: None})\n",
    "agg2['dt'] = agg2.index.values\n",
    "#agg2['dt'] = agg2['dt'].apply(lambda x: x.to_pydatetime().isoformat())\n",
    "agg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "basement_tmp = agg2.copy(deep=True)[agg2['temp_basement']][['temp_basement']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}