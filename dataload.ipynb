{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"C:\\\\Users\\\\T834432\\\\Documents\\\\personnel\\\\thermostat\\\\thermostat-agent\\\\thermostat-292016-05700c0efdbe__.json\"\n",
    "os.environ[\"PROJECT_ID\"] = \"thermostat-292016\"\n",
    "os.environ[\"ACTION_THRESHOLD\"] = \"1.0\"\n",
    "\n",
    "from google.cloud import storage\n",
    "#from thermostat import get_metric_list_from_bucket, bucket_name, storage_client\n",
    "from yadt import parse_date, apply_tz_toronto\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Instantiates a client\n",
    "storage_client = storage.Client()\n",
    "# The name for the new bucket\n",
    "bucket = storage_client.bucket(\"thermostat_metric_data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = bucket.get_blob('_thermostat_metric_data.p')\n",
    "\n",
    "pickle_load = b.download_as_bytes()\n",
    "thermostat_metric_data = pickle.loads(pickle_load)\n",
    "thermostat_metric_data.sort_index(inplace=True)\n",
    "#thermostat_metric_data['hash'] = pd.util.hash_pandas_object(thermostat_metric_data)\n",
    "#thermostat_metric_data = thermostat_metric_data[~thermostat_metric_data.duplicated(keep='first')]\n",
    "thermostat_metric_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from yadt import scan_and_apply_tz, utcnow\n",
    "import json\n",
    "from datetime import datetime\n",
    "from thermostat_aggregation_utils import aggregate_to_dataframe, metric_str_to_json\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "thermostat_metric_data = pd.DataFrame()\n",
    "#onlyfiles = [f for f in listdir('dump') if isfile(join('dump', f))]\n",
    "#onlyfiles.reverse()\n",
    "\n",
    "\n",
    "onlyfiles = [\n",
    "    f for f in listdir('dump') if isfile(join('dump', f)) and (\n",
    "        f.startswith('thermostat-')\n",
    "        or f.startswith('environment_sensor_basement-'))\n",
    "]\n",
    "\n",
    "#existing_files = set(thermostat_metric_data['filename'].tolist())\n",
    "#onlyfiles = set(onlyfiles) - existing_files\n",
    "\n",
    "print(f\"Files to process : {len(onlyfiles)}\")\n",
    "\n",
    "load_date = utcnow()\n",
    "\n",
    "exist = 0\n",
    "processed = 0\n",
    "for f in tqdm(onlyfiles):\n",
    "\n",
    "    with open('dump/'+f, 'r') as file:\n",
    "        data = file.read().replace('\\n', '')\n",
    "        #print(f)\n",
    "        try:\n",
    "            last_json = metric_str_to_json(data)\n",
    "            \n",
    "            merge, thermostat_metric_data = aggregate_to_dataframe(f,last_json, thermostat_metric_data, load_date)\n",
    "\n",
    "\n",
    "            if merge:\n",
    "                #print(f\"Import {f}\")\n",
    "                processed = processed + 1\n",
    "            else:\n",
    "                #print(f\"PASS - {f}\")\n",
    "                exist = exist+1\n",
    "            \n",
    "            #if exist > 200:\n",
    "                #break\n",
    "            \n",
    "        except Exception as e:\n",
    "            raise e\n",
    "            #else:\n",
    "            #    pass\n",
    "            #print(data)\n",
    "\n",
    "thermostat_metric_data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#thermostat_metric_data['location'] = thermostat_metric_data.apply(lambda x : x['site'] if pd.isna(x['location']) else x['location'], axis = 1)\n",
    "#thermostat_metric_data = thermostat_metric_data[~thermostat_metric_data.duplicated(keep='first')]\n",
    "thermostat_metric_data.sort_index(inplace=True)\n",
    "thermostat_metric_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_dump = pickle.dumps(thermostat_metric_data)\n",
    "b = bucket.blob('_thermostat_metric_data.p')\n",
    "b.temporary_hold = False\n",
    "b.patch()\n",
    "b.upload_from_string(data=pickle_dump, content_type='text/plain')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump(thermostat_metric_data,open( \"test/_thermostat_metric_data.p\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 200)\n",
    "\n",
    "thermostat_metric_data.tail(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}